{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from spacy.lang.en import English\n",
    "from transformers import CONFIG_MAPPING, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "nlp = English()\n",
    "tokenizer = nlp.tokenizer\n",
    "path = 'data/e2e_data/src1_train.txt'\n",
    "with open(path, 'r') as ff:\n",
    "    for row in ff:\n",
    "        word_lst = row.split('||')[1]\n",
    "        word_lst = [x.text for x in tokenizer(word_lst)]\n",
    "        train_dataset.append(word_lst)\n",
    "\n",
    "counter = Counter()\n",
    "for input_ids in train_dataset:\n",
    "    counter.update(input_ids)\n",
    "\n",
    "vocab = {'START': 0, 'END': 1, 'UNK':2, 'PAD':3}\n",
    "for k, v in counter.items():\n",
    "    if v > 10:\n",
    "        vocab[k] = len(vocab)\n",
    "\n",
    "train_datasets = Dataset.from_dict({'text': train_dataset})\n",
    "raw_datasets = train_datasets.train_test_split(0.01)\n",
    "raw_datasets.vocab = vocab\n",
    "raw_datasets['validation'] = raw_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CONFIG_MAPPING['gpt2']()\n",
    "\n",
    "tokenizer = raw_datasets.vocab\n",
    "reverse_tokenizer = {v: k for k, v in tokenizer.items()}\n",
    "\n",
    "config.vocab_size = len(tokenizer)\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "column_names = raw_datasets[\"train\"].column_names\n",
    "text_column_name = \"text\" if \"text\" in column_names else column_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    vocab_dict = raw_datasets.vocab\n",
    "    input_ids = [[0] + [vocab_dict.get(x, vocab_dict['UNK']) for x in seq] + [1] for seq in examples['text']]\n",
    "    return {'input_ids': input_ids}\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 64\n",
    "\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i: i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=4)\n",
    "\n",
    "train_dataset = lm_datasets[\"train\"]\n",
    "eval_dataset = lm_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    print(logits[0].shape, logits[1].shape)\n",
    "    if type(logits) == tuple:\n",
    "        return logits[0].argmax(dim=-1)\n",
    "    else:\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    preds = preds[:, :-1].reshape(-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
